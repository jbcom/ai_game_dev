name: Cross-Language Static Analysis & Code Coverage

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  RUST_VERSION: '1.70'

jobs:
  python-analysis:
    name: Python Static Analysis
    runs-on: ubuntu-latest
    strategy:
      matrix:
        tool: [mypy, pylint, bandit, ruff]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install UV
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev
          uv add gdtoolkit

      - name: Run MyPy
        if: matrix.tool == 'mypy'
        run: |
          uv run mypy src/ai_game_dev/ --config-file pyproject.toml
          uv run mypy src/ai_game_dev/ --config-file pyproject.toml --html-report mypy-report

      - name: Run Pylint
        if: matrix.tool == 'pylint'
        run: |
          uv run pylint src/ai_game_dev/ --output-format=json > pylint-report.json || true
          uv run pylint src/ai_game_dev/ --output-format=text

      - name: Run Bandit Security Analysis
        if: matrix.tool == 'bandit'
        run: |
          uv run bandit -r src/ai_game_dev/ -f json -o bandit-report.json || true
          uv run bandit -r src/ai_game_dev/ -f txt

      - name: Run Ruff Linting
        if: matrix.tool == 'ruff'
        run: |
          uv run ruff check src/ai_game_dev/ --output-format=json > ruff-report.json || true
          uv run ruff check src/ai_game_dev/

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: python-${{ matrix.tool }}-analysis
          path: |
            mypy-report/
            pylint-report.json
            bandit-report.json
            ruff-report.json


  code-coverage:
    name: Code Coverage Analysis
    runs-on: ubuntu-latest
    needs: [python-analysis]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install UV
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev

      - name: Run Python test coverage
        run: |
          uv run pytest tests/ --cov=src/ai_game_dev --cov-branch --cov-report=xml --cov-report=html --cov-report=term-missing

      - name: Generate coverage badge
        run: |
          uv run coverage-badge -o coverage-badge.svg

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: |
            htmlcov/
            coverage.xml
            coverage-badge.svg


  quality-gates:
    name: Quality Gates & Reporting
    runs-on: ubuntu-latest
    needs: [python-analysis, code-coverage]
    if: always()
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download all analysis artifacts
        uses: actions/download-artifact@v3
        with:
          path: analysis-reports

      - name: Setup Python for reporting
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Generate unified quality report
        run: |
          python .github/scripts/generate_quality_report.py

      - name: Comment PR with quality report
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('quality-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

      - name: Upload unified quality report
        uses: actions/upload-artifact@v3
        with:
          name: quality-dashboard
          path: |
            quality-report.md
            quality-report.html

  security-scan:
    name: Security Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Run CodeQL Analysis
        uses: github/codeql-action/init@v3
        with:
          languages: python

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  performance-analysis:
    name: Performance Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install UV and dependencies
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          uv sync --all-extras --dev
          uv add py-spy memory-profiler

      - name: Run performance profiling
        run: |
          uv run python -m pytest tests/ -v --benchmark-only --benchmark-json=benchmark-results.json || true

      - name: Memory profiling
        run: |
          uv run mprof run python -c "
          from ai_game_dev import create_game, create_educational_game
          # Basic memory usage test
          " || true
          uv run mprof plot -o memory-profile.png || true

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v3
        with:
          name: performance-analysis
          path: |
            benchmark-results.json
            memory-profile.png
            mprofile_*.dat